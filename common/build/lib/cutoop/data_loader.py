"""
Dataset and Loading Functions
=============================
"""

from functools import partial
import glob
import os
from PIL import Image as _Image
import warnings

from .image_meta import ImageMetaData
from .align import estimateSimilarityTransform
from .transform import depth2xyz
from .utils import draw_3d_bbox, draw_object_label, draw_pose_axes
from .data_types import Pose
from .image_meta import ImageMetaData

os.environ["OPENCV_IO_ENABLE_OPENEXR"] = "1"  # before importing cv2
import cv2
import numpy as np


class Dataset(object):
    """This class can be used as a base class for dataloader construction."""

    @staticmethod
    def load_meta(path: str) -> ImageMetaData:
        """See :meth:`.image_meta.ImageMetaData.load_json`."""
        return ImageMetaData.load_json(path)

    @staticmethod
    def load_color(path: str) -> np.ndarray:
        """Load RGB image in **RGB** order."""
        data = cv2.imread(path)[:, :, ::-1]  # RGB order
        return data

    @staticmethod
    def load_coord(path: str) -> np.ndarray:
        """Read NOCS image (PNG). This function does the following things:

        1. Read, normalize, and transform the image into **RGB** order.
        2. Due to historical reasons, the ``B`` channel is transformed to ``1 - B`` after
           reading the image, which is a common transformation for other NOCS image in prior
           datasets.
        3. Minus `0.5` to change the range of pixel values from `[0, 1]` to `[-0.5, 0.5]`.

        :return: float array of shape (Height, Width) ranged [-0.5, 0.5], denothing xyz coordinates in NOCS space
        """
        # set_trace()
        img = cv2.imread(path, cv2.IMREAD_UNCHANGED).astype(np.float32) / 255
        # https://stackoverflow.com/questions/50963283/imshow-doesnt-need-convert-from-bgr-to-rgb
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = img.clip(0, 1)
        img[:, :, 2] = 1 - img[:, :, 2]  # 1 - z

        return img - 0.5

    @staticmethod
    def load_ir(path: str) -> np.ndarray:
        """Load the rendered IR image"""
        data = _Image.open(path).convert("L")
        return np.array(data)

    @staticmethod
    def load_depth(path: str) -> np.ndarray:
        """
        This function read the depth image, selecting the first channel if multiple
        channels are detected.

        :return: A 2D float array of shape (Height, Width). For Omni6DPose,
            the unit of pixel value is meter.
        """
        img = cv2.imread(path, cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)
        if len(img.shape) == 3:
            img = img[:, :, 0]
        return img  # unit: m

    @staticmethod
    def load_mask(path: str) -> np.ndarray:
        """Load the mask image.

        :return: uint8 array of shape (Height, Width), whose values are related
            to the objects' mask ids (:attr:`.image_meta.ObjectPoseInfo.mask_id`).
        """
        img = cv2.imread(path, cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)
        if len(img.shape) == 3:
            img = img[:, :, 2]
        return np.array(img * 255, dtype=np.uint8)

    @staticmethod
    def load_mask_sam(path: str) -> "tuple[np.ndarray, np.ndarray]":
        """Load the mask generated by SAM.

        :return: (masks, mask_ids) where masks is bool array of shape (n_objects, Height, Width)
            denoting the binary mask of each objects corresponds to mask_ids, whose shape is (n_objects,).
        """
        data = np.load(path)
        masks = data["masks"]
        mask_ids = data["mask_ids"]
        return masks, mask_ids

    @staticmethod
    def load_normal(path: str) -> np.ndarray:
        """Read normal image (exr)

        :return: float array of shape (H, W, 3) ranged [-1, 1] containing normal vectors
        """
        img = cv2.imread(path, cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img[:, :, 0] = 0 - img[:, :, 0]  # x => -x
        return img

    LOADER_MAP = {
        "color": ("color.png", load_color),
        "coord": ("coord.png", load_coord),
        "ir_l": ("ir_l.png", load_ir),
        "ir_r": ("ir_r.png", load_ir),
        "depth": ("depth.exr", load_depth),
        "depth_syn": ("depth_syn.exr", load_depth),
        "mask": ("mask.exr", load_mask),
        "mask_sam": ("mask_sam.npz", load_mask_sam),
        "normal": ("normal.exr", load_normal),
        "meta": ("meta.json", load_meta),
    }

    def visualize_by(
        vis_img: np.ndarray,
        prefix: str,
        show_id=True,
        show_box=True,
        show_nocs_pred=False,
        show_axes_len: "float | None" = None,
    ):
        metadata = Dataset.load_meta(prefix + "meta.json")
        masks = Dataset.load_mask(prefix + "mask.exr")
        intrinsics = metadata.camera.intrinsics
        depth_pts = depth2xyz(Dataset.load_depth(prefix + "depth.exr"), intrinsics)
        if show_nocs_pred:
            coords = Dataset.load_coord(prefix + "coord.png")
        # set_trace()

        bbox_task = []
        label_task = []
        for i, data in enumerate(metadata.objects):
            idx = tuple(np.argwhere(masks == data.mask_id).T)
            pts = depth_pts[idx]
            if show_nocs_pred:
                coord = coords[idx]

            bbox_side_len = data.meta.bbox_side_len
            obj_pose = Pose(
                quaternion=data.quaternion_wxyz, translation=data.translation
            )
            if show_box:
                bbox_task.append(
                    partial(
                        draw_3d_bbox,
                        intrinsics=intrinsics,
                        sRT_4x4=obj_pose.to_affine(),
                        bbox_side_len=bbox_side_len,
                    )
                )
            if show_axes_len is not None:
                bbox_task.append(
                    partial(
                        draw_pose_axes,
                        intrinsics=intrinsics,
                        sRT_4x4=obj_pose.to_affine(),
                        length=show_axes_len,
                    )
                )

            # set_trace()
            if show_nocs_pred and show_box:
                _, _, _, pred_sRT = estimateSimilarityTransform(coord, pts)
                bbox_task.append(
                    partial(
                        draw_3d_bbox,
                        intrinsics=intrinsics,
                        sRT_4x4=pred_sRT,
                        bbox_side_len=2 * np.amax(np.abs(coord), axis=0),
                    )
                )
            if show_id:
                label_task.append(
                    partial(
                        draw_object_label,
                        intrinsics=intrinsics,
                        sRT_4x4=obj_pose.to_affine(),
                        label=str(i),
                    )
                )

        for filter in bbox_task:
            vis_img = filter(img=vis_img)
        for filter in label_task:
            vis_img = filter(img=vis_img)

        return vis_img

    def visualize(
        prefix: str,
        out_path="./visual.png",
        show_id=True,
        show_box=True,
        show_nocs_pred=False,
        show_axes_len=None,
    ):
        """A convenient helper for data visualization.

        .. doctest::

            >>> cutoop.data_loader.Dataset.visualize(
            ...     prefix="../../misc/sample_real/000000_",
            ...     out_path="source/_static/gr_5.png",
            ... )

        .. image:: _static/gr_5.png
            :align: center
        """
        color = Dataset.load_color(prefix + "color.png")
        vis_img = Dataset.visualize_by(
            color,
            prefix,
            show_id=show_id,
            show_box=show_box,
            show_nocs_pred=show_nocs_pred,
            show_axes_len=show_axes_len,
        )
        vis_img = cv2.cvtColor(vis_img, cv2.COLOR_RGB2BGR)
        cv2.imwrite(out_path, vis_img)

    @staticmethod
    def glob_prefix(root: str) -> "list[str]":
        """Recursively find the prefix list of data (by RGB image).

        Since we use the `glob` package for image searching, you may use the asterisk
        symbol ``*`` for pattern matching. However, since we internally use the ``**``
        pattern, you're not encouraged to use ``**`` to avoid duplicated prefix outputs.

        :param root: the root directory for searching.

        .. doctest::

            >>> cutoop.data_loader.Dataset.glob_prefix("../../misc")
            ['../../misc/sample/0000_', '../../misc/sample/0001_', '../../misc/sample/0002_', '../../misc/sample_real/000000_']
            >>> cutoop.data_loader.Dataset.glob_prefix("../../*/sample")
            ['../../misc/sample/0000_', '../../misc/sample/0001_', '../../misc/sample/0002_']

        """
        dirs = [root]
        prefixes: list[str] = []
        for dir in dirs:
            prefs = [
                path[:-9]
                for path in glob.glob(
                    os.path.join(dir, "**/*_color.png"), recursive=True
                )
            ]
            prefixes.extend(prefs)
        return sorted(prefixes)
